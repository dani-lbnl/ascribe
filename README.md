# ASCRIBE 
This work is part of the ASCRIBE project, visit our [website](https://sites.google.com/lbl.gov/ascribe).
- ASCRIBE stands for Autonomous Solutions for Computational Research with Immersive Browsing & Exploration.
- A Berkeley Lab project developing Virtual Reality (VR) platforms for scientific research, integrating advanced algorithms with large-scale scientific images.
- Enables multimodal analysis, structural assessments, and immersive visualization of complex datasets (e.g., X-ray CT, MRI, synthetic 3D imaging).
- Offers seamless exploration of large 3D images using VR tools compatible with platforms like Meta Quest.
  
<table border="0">
 <tr>
    <td><a href='https://www.youtube.com/watch?v=2mkX79KLKEs'><img src="https://github.com/dani-lbnl/ascribe/blob/main/ascribe4materials.jpg" width="300"></a>
    </td>
  <td><img src="https://github.com/dani-lbnl/ascribe/blob/main/ascribeXR-menu.jpg" width="300">
    </td>
  </tr>
  </table>

# Microstructure Visualization using ASCRIBE VR Platforms

Twice the Fun, Twice the Tech! See our ASCRIBE VR Labs—powered by Unreal AND Godot for the visualization of scientific data microstructures. It is designed and optimized for immersive experiences using Meta Quest 3 and Meta Quest 3s.

## Overview

This repository's main goal is to enable high-quality, real-time visualization of microstructures in virtual reality. The visualization tools allow researchers, engineers, and instructors to explore detailed microstructural models interactively in VR.

## Features

- **Immersive Visualization:** Fully immersive VR interaction tailored specifically for Meta Quest 3 and Quest 3s.
- **High-Resolution Rendering:** Optimized rendering settings for clear visualization of microstructural details.
- **Example Assets:** Includes a collection of mesh examples representing typical microstructures.

## Requirements

- Unreal Engine 5.x
- Meta Quest 3 or Quest 3s headset
- Oculus Link or Air Link setup

## Setup Instructions

1. **Email us to request a demo**
2. **More coming up soon**
   

## About the project:

ASCRIBE (Autonomous Solutions for Computational Research with Immersive Browsing & Exploration) is a pioneering research project at the nexus of AI and Extended Reality (XR), designed to revolutionize scientific visualization and accelerate discovery. This initiative aims to develop AI-based algorithms for an integrated platform that leverages multimodal data, structural/chemical analyses, and immersive visualization for interactive exploration. ASCRIBE is uniquely positioned through strategic partnerships with leading centers, including CAMERA, CIWE, and Restor-C, granting access to advanced data sources such as X-ray CT, FIB-SEM, cryo-TEM, time-lapse plant imaging, and simulations, facilitating the creation of digital twins. ASCRIBE is structured around five core functionalities: data filtering, segmentation, quantification, immersion, and interaction. Tailored routines preprocess data to handle noise, anisotropy, and alignment, while AI-based semantic segmentation, steered by Gaussian Processes, enables precise calculation of Volumes of Interest (VOI) and other measurements. Prior-based postprocessing and validation are achieved through AI-driven autonomous loops, providing iterative feedback and uncertainty quantification. For immersive exploration, ASCRIBE develops XR-tools compatible with Meta Quest, powered by Unreal and Godot Engine and adhering to OpenXR standards, allowing ingestion and visualization of raw and reduced data, including VOI-based polygonal meshes and volume renderings. By integrating key technologies such as alignment, anisotropic diffusion, CNNs, viTs, LLMs, VTK, etc., ASCRIBE enhances how we visualize the outcomes of computer vision solutions, exemplified in structural analysis of water electrolyzer membranes. This convergence of AI and XR creates a sense of "presence", enabling researchers to explore complex concepts in virtual environments, accelerating scientific discovery in micro/nanostructure, and materials design.

### Cite this work:
```bibtex
@inproceedings{Pandolfi2025ASCRIBEXR,
  author    = {Pandolfi, Ronald, Donatelli and Jeffrey and Todd, Julian and Ushizima, Daniela},
  title     = {{ASCRIBE-XR: Extended Reality for Visualization of Scientific Images}},
  booktitle = {Proceedings of the 11th IEEE/ACM Workshop on Data Reduction for Scientific Data (DRBSD-11)},
  series    = {Supercomputing 25 (SC '25)},
  year      = {2025},
  doi       = {10.1145/3731599.3767368},
  url       = {https://doi.org/10.1145/3731599.3767368}
}

@misc{ushizima2025ascribenewdimensionsscientific,
      title={Ascribe New Dimensions to Scientific Data Visualization with VR}, 
      author={Daniela Ushizima and Guilherme Melo dos Santos and Zineb Sordo and Ronald Pandolfi and Jeffrey Donatelli},
      year={2025},
      eprint={2504.13448},
      archivePrefix={arXiv},
      primaryClass={cs.GR},
      url={https://arxiv.org/abs/2504.13448}, 
}


Warning: This repo is under active development, so use it at your own risk. Found a bug? File an issue or contact [Dani Ushizima](mailto:dani.lbnl@gmail.com)
